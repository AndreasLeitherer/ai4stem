{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bd014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: start with fcc image, then see transition and all these features\n",
    "# then add more images, Ti for example, and then add Fe bcc as final example.\n",
    "# maybe precalculate the hidden reps\n",
    "# Add visualization feature where can hover over the images and sees them.\n",
    "# Better to provide pre-calculated values and then some code how to do it for \n",
    "# new images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd00845",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use UMAP, a manifold learning algorithm, to inspect the internal neural-network representations of AI-STEM that are learned during training. We will consider an experimental image (Fe bcc [100]) as an example. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90af9a40",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301a4a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdb993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# tensorflow info/warnings switched off\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from ai4stem.utils.utils_data import load_pretrained_model, load_example_image\n",
    "from ai4stem.utils.utils_prediction import predict\n",
    "\n",
    "from ai4stem.utils.utils_fft import calc_fft\n",
    "from ai4stem.utils.utils_prediction import localwindow\n",
    "from ai4stem.utils.utils_nn import decode_preds, predict_with_uncertainty\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import umap\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db4e2f9",
   "metadata": {},
   "source": [
    "# Load example image and specify AI-STEM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a9f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path where to save the results:\n",
    "results_folder = '.'\n",
    "\n",
    "# load image\n",
    "input_image = load_example_image()\n",
    "image_name = 'Fe_bcc'\n",
    "# image specifications\n",
    "pixel_to_angstrom = 0.12452489444788318\n",
    "# AI-STEM parameters\n",
    "window_size = 12.\n",
    "stride_size = [36, 36]\n",
    "# convert window [Angstrom] to window [pixels]\n",
    "adapted_window_size = int(window_size * (1. / pixel_to_angstrom))\n",
    "print(adapted_window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c37bdb",
   "metadata": {},
   "source": [
    "# Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bad0827",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_pretrained_model()\n",
    "model_name = 'pretrained_model'\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40803d9",
   "metadata": {},
   "source": [
    "# Segment image and calculate FFT-HAADF descriptor (i.e., the neural-network input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efdb7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc fft\n",
    "sliced_images, spm_pos, ni, nj = localwindow(input_image, stride_size=stride_size, pixel_max=adapted_window_size)\n",
    "\n",
    "logger.info('Calculate FFT-HAADF descriptor.')\n",
    "fft_descriptors = []\n",
    "for im in sliced_images:\n",
    "    fft_desc = calc_fft(im, sigma=None, thresholding=True)\n",
    "    fft_descriptors.append(fft_desc)\n",
    "    \n",
    "# reshape such that matches model input shape\n",
    "data = np.array([np.stack([_]) for _ in fft_descriptors])\n",
    "data = np.moveaxis(data, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ac8e27",
   "metadata": {},
   "source": [
    "# Extract internal neural-network representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907df0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model, where remove last classification layer\n",
    "\n",
    "inputs = model.input\n",
    "# select layer before last classification layer\n",
    "# as new final layer:\n",
    "outpout_layer_name = 'Dense_1' \n",
    "outputs = model.get_layer(outpout_layer_name).output\n",
    "intermediate_layer_model = Model(inputs=inputs,\n",
    "                                 outputs=outputs)\n",
    "intermediate_layer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab63dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute representations\n",
    "nn_representations = decode_preds(data, intermediate_layer_model, n_iter=100)\n",
    "prediction, uncertainty = predict_with_uncertainty(data, model, \n",
    "                                                   model_type='classification', \n",
    "                                                   n_iter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1eca05",
   "metadata": {},
   "source": [
    "# Apply UMAP and visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5308e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dictionaries for visalizing\n",
    "layer_activations = {'nn_rep': nn_representations}\n",
    "targets = {'nn_rep': {'argmax': prediction.argmax(axis=-1), 'mut_info': uncertainty['mutual_information']}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08197dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply UMAP\n",
    "\n",
    "# most important parameter:\n",
    "# number of neighbors employed\n",
    "# for calculating low-dimensional (here, 2D)\n",
    "# embedding\n",
    "n_neighbors_list = [5, 50, 200]\n",
    "# choose Euclidean metric\n",
    "# for measuring distance between data points\n",
    "metric = 'euclidean'\n",
    "# Choose 2 as embedding dimension\n",
    "n_components = 2\n",
    "# plotting parameters\n",
    "s = 2.5\n",
    "edgecolors = 'face'\n",
    "\n",
    "for n_neighbors in n_neighbors_list:\n",
    "    logger.info('Apply UMAP for number of neighbors = {}'.format(n_neighbors))\n",
    "\n",
    "    for key in layer_activations:\n",
    "        \n",
    "        data_for_fitting = layer_activations[key]\n",
    "\n",
    "        mapper1 = umap.UMAP(n_neighbors=n_neighbors, \n",
    "                            metric=metric, \n",
    "                            n_components=n_components).fit(data_for_fitting)\n",
    "        embedding = mapper1.transform(data_for_fitting)\n",
    "\n",
    "        for target in targets[key]:\n",
    "            cmap = None\n",
    "            nber_unique_colors = np.unique(targets[key][target]).size\n",
    "            if target == 'mut_info':\n",
    "                cmap = 'hot'\n",
    "            else:\n",
    "                cmap = 'tab10'\n",
    "            fig, axs = plt.subplots(facecolor='white', figsize=(10, 10))\n",
    "            df = pd.DataFrame({'e1': embedding[:, 0], 'e2': embedding[:, 1], 'target': targets[key][target]})\n",
    "            \n",
    "            if target == 'argmax_pred':\n",
    "                df['target'] = [text_to_numerical_label[_] for _ in df['target'].values]\n",
    "            \n",
    "            im = axs.scatter(df['e1'].values, df['e2'].values, c=df['target'], cmap=cmap, s=s)\n",
    "            axs.set_aspect('equal')\n",
    "            fig.colorbar(im, ax=axs)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # uncomment if want to save\n",
    "            #plt.savefig('{}_{}_nn_{}_embedding.png'.format(key, target, n_neighbors), dpi=200)\n",
    "            #plt.close()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d50f7d",
   "metadata": {},
   "source": [
    "# Repeat analysis for several images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6832c4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_link_fcc = 'https://www.dropbox.com/s/flfy5qe1qxv47t6/Cu_fcc_111.npy?dl=0'\n",
    "download_link_bcc = 'https://www.dropbox.com/s/ukab367rktmddse/Fe_bcc_100.npy?dl=0'\n",
    "download_link_hcp = 'https://www.dropbox.com/s/q4rvqcy87u3ath9/Ti_hcp_0001.npy?dl=0'\n",
    "\n",
    "!wget -q $download_link_fcc -O 'Cu_fcc_100.npy'\n",
    "!wget -q $download_link_bcc -O 'Fe_bcc_100.npy'\n",
    "!wget -q $download_link_hcp -O 'Ti_hcp_0001.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caa600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [np.load('Cu_fcc_100.npy'),\n",
    "          np.load('Fe_bcc_100.npy'),\n",
    "          np.load('Ti_hcp_0001.npy')]\n",
    "\n",
    "image_names = ['Cu_fcc_100',\n",
    "               'Fe_bcc_100',\n",
    "               'Ti_hcp_0001']\n",
    "\n",
    "window_size = 12. # units: Angstrom\n",
    "\n",
    "pixel_to_angstrom= [0.088052397290637275,\n",
    "                    0.12452489,\n",
    "                    0.12452489]\n",
    "\n",
    "strides = [[12, 12], [6, 6], [12, 12]]\n",
    "strides = [[36, 36], [36, 36], [36, 36]]\n",
    "\n",
    "adapted_window_sizes = [int(window_size * (1. / ratio)) for ratio in  pixel_to_angstrom]\n",
    "print(adapted_window_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9d1a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20,20))\n",
    "axs[0].imshow(images[0], cmap='gray')\n",
    "axs[0].set_title('Cu fcc [100]')\n",
    "axs[1].imshow(images[1], cmap='gray')\n",
    "axs[1].set_title('Fe bcc [100]')\n",
    "axs[2].imshow(images[2], cmap='gray')\n",
    "axs[2].set_title('Ti hcp [0001]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ccda14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_descriptors = []\n",
    "for idx, input_image in enumerate(images):\n",
    "    \n",
    "    stride_size = strides[idx]\n",
    "    adapted_window_size = adapted_window_sizes[idx]\n",
    "    image_name = image_names[idx]\n",
    "    \n",
    "    logger.info('Extract local fragments for image {}.'.format(image_name))\n",
    "    # calc fft\n",
    "    sliced_images, spm_pos, ni, nj = localwindow(input_image, \n",
    "                                                 stride_size=stride_size, \n",
    "                                                 pixel_max=adapted_window_size)\n",
    "\n",
    "    logger.info('Calculate FFT-HAADF descriptor for image {}.'.format(image_name))\n",
    "    \n",
    "    for im in sliced_images:\n",
    "        fft_desc = calc_fft(im, sigma=None, thresholding=True)\n",
    "        fft_descriptors.append(fft_desc)\n",
    "\n",
    "# reshape such that matches model input shape\n",
    "data = np.array([np.stack([_]) for _ in fft_descriptors])\n",
    "data = np.moveaxis(data, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d62dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model, where remove last classification layer\n",
    "\n",
    "inputs = model.input\n",
    "# select layer before last classification layer\n",
    "# as new final layer:\n",
    "outpout_layer_name = 'Dense_1' \n",
    "outputs = model.get_layer(outpout_layer_name).output\n",
    "intermediate_layer_model = Model(inputs=inputs,\n",
    "                                 outputs=outputs)\n",
    "intermediate_layer_model.summary()\n",
    "\n",
    "\n",
    "# Compute representations\n",
    "nn_representations = decode_preds(data, intermediate_layer_model, n_iter=10)\n",
    "prediction, uncertainty = predict_with_uncertainty(data, model, \n",
    "                                                   model_type='classification', \n",
    "                                                   n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b6fc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dictionaries for visalizing\n",
    "layer_activations = {'nn_rep': nn_representations}\n",
    "targets = {'nn_rep': {'argmax': prediction.argmax(axis=-1), 'mut_info': uncertainty['mutual_information']}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aa01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply UMAP\n",
    "\n",
    "# most important parameter:\n",
    "# number of neighbors employed\n",
    "# for calculating low-dimensional (here, 2D)\n",
    "# embedding\n",
    "n_neighbors_list = [5, 50, 200]\n",
    "# choose Euclidean metric\n",
    "# for measuring distance between data points\n",
    "metric = 'euclidean'\n",
    "# Choose 2 as embedding dimension\n",
    "n_components = 2\n",
    "# plotting parameters\n",
    "s = 2.5\n",
    "edgecolors = 'face'\n",
    "\n",
    "for n_neighbors in n_neighbors_list:\n",
    "    logger.info('Apply UMAP for number of neighbors = {}'.format(n_neighbors))\n",
    "\n",
    "    for key in layer_activations:\n",
    "        \n",
    "        data_for_fitting = layer_activations[key]\n",
    "\n",
    "        mapper1 = umap.UMAP(n_neighbors=n_neighbors, \n",
    "                            metric=metric, \n",
    "                            n_components=n_components).fit(data_for_fitting)\n",
    "        embedding = mapper1.transform(data_for_fitting)\n",
    "\n",
    "        for target in targets[key]:\n",
    "            cmap = None\n",
    "            nber_unique_colors = np.unique(targets[key][target]).size\n",
    "            if target == 'mut_info':\n",
    "                cmap = 'hot'\n",
    "            else:\n",
    "                cmap = 'tab10'\n",
    "            fig, axs = plt.subplots(facecolor='white', figsize=(10, 10))\n",
    "            df = pd.DataFrame({'e1': embedding[:, 0], 'e2': embedding[:, 1], 'target': targets[key][target]})\n",
    "            \n",
    "            if target == 'argmax_pred':\n",
    "                df['target'] = [text_to_numerical_label[_] for _ in df['target'].values]\n",
    "            \n",
    "            im = axs.scatter(df['e1'].values, df['e2'].values, c=df['target'], cmap=cmap, s=s)\n",
    "            axs.set_aspect('equal')\n",
    "            fig.colorbar(im, ax=axs)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # uncomment if want to save\n",
    "            #plt.savefig('{}_{}_nn_{}_embedding.png'.format(key, target, n_neighbors), dpi=200)\n",
    "            #plt.close()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18389007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec95c0cf",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use UMAP, a manifold learning algorithm, to inspect the internal neural-network representations of AI-STEM that are learned during training. We will consider an experimental image (Fe bcc [100]) as an example. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22b4790",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b0f28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c1f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# tensorflow info/warnings switched off\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from ai4stem.utils.utils_data import load_pretrained_model, load_example_image\n",
    "from ai4stem.utils.utils_prediction import predict\n",
    "\n",
    "from ai4stem.utils.utils_fft import calc_fft\n",
    "from ai4stem.utils.utils_prediction import localwindow\n",
    "from ai4stem.utils.utils_nn import decode_preds, predict_with_uncertainty\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import umap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40fc931",
   "metadata": {},
   "source": [
    "# Load example image and specify AI-STEM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path where to save the results:\n",
    "results_folder = '.'\n",
    "\n",
    "# load image\n",
    "input_image = load_example_image()\n",
    "image_name = 'Fe_bcc'\n",
    "# image specifications\n",
    "pixel_to_angstrom = 0.12452489444788318\n",
    "# AI-STEM parameters\n",
    "window_size = 12.\n",
    "stride_size = [36, 36]\n",
    "# convert window [Angstrom] to window [pixels]\n",
    "adapted_window_size = int(window_size * (1. / pixel_to_angstrom))\n",
    "print(adapted_window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7712794",
   "metadata": {},
   "source": [
    "# Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5ba56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_pretrained_model()\n",
    "model_name = 'pretrained_model'\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0190fd",
   "metadata": {},
   "source": [
    "# Segment image and calculate FFT-HAADF descriptor (i.e., the neural-network input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a752bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc fft\n",
    "sliced_images, spm_pos, ni, nj = localwindow(input_image, stride_size=stride_size, pixel_max=adapted_window_size)\n",
    "\n",
    "logger.info('Calculate FFT-HAADF descriptor.')\n",
    "fft_descriptors = []\n",
    "for im in sliced_images:\n",
    "    fft_desc = calc_fft(im, sigma=None, thresholding=True)\n",
    "    fft_descriptors.append(fft_desc)\n",
    "    \n",
    "# reshape such that matches model input shape\n",
    "data = np.array([np.stack([_]) for _ in fft_descriptors])\n",
    "data = np.moveaxis(data, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241ae2a8",
   "metadata": {},
   "source": [
    "# Extract internal neural-network representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a34c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model, where remove last classification layer\n",
    "\n",
    "inputs = model.input\n",
    "# select layer before last classification layer\n",
    "# as new final layer:\n",
    "outpout_layer_name = 'Dense_1' \n",
    "outputs = model.get_layer(outpout_layer_name).output\n",
    "intermediate_layer_model = Model(inputs=inputs,\n",
    "                                 outputs=outputs)\n",
    "intermediate_layer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398eb192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute representations\n",
    "nn_representations = decode_preds(data, intermediate_layer_model, n_iter=100)\n",
    "prediction, uncertainty = predict_with_uncertainty(data, model, \n",
    "                                                   model_type='classification', \n",
    "                                                   n_iter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06ad3ea",
   "metadata": {},
   "source": [
    "# Apply UMAP and visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fb3526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dictionaries for visalizing\n",
    "layer_activations = {'nn_rep': nn_representations}\n",
    "targets = {'nn_rep': {'argmax': prediction.argmax(axis=-1), 'mut_info': uncertainty['mutual_information']}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc1745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply UMAP\n",
    "\n",
    "# most important parameter:\n",
    "# number of neighbors employed\n",
    "# for calculating low-dimensional (here, 2D)\n",
    "# embedding\n",
    "n_neighbors_list = [5, 50, 200]\n",
    "# choose Euclidean metric\n",
    "# for measuring distance between data points\n",
    "metric = 'euclidean'\n",
    "# Choose 2 as embedding dimension\n",
    "n_components = 2\n",
    "# plotting parameters\n",
    "s = 2.5\n",
    "edgecolors = 'face'\n",
    "\n",
    "for n_neighbors in n_neighbors_list:\n",
    "    logger.info('Apply UMAP for number of neighbors = '.format(n_neighbors))\n",
    "\n",
    "    for key in layer_activations:\n",
    "        \n",
    "        data_for_fitting = layer_activations[key]\n",
    "\n",
    "        mapper1 = umap.UMAP(n_neighbors=n_neighbors, \n",
    "                            metric=metric, \n",
    "                            n_components=n_components).fit(data_for_fitting)\n",
    "        embedding = mapper1.transform(data_for_fitting)\n",
    "\n",
    "        for target in targets[key]:\n",
    "            cmap = None\n",
    "            nber_unique_colors = np.unique(targets[key][target]).size\n",
    "            if target == 'mut_info':\n",
    "                cmap = 'hot'\n",
    "            else:\n",
    "                cmap = 'tab10'\n",
    "            fig, axs = plt.subplots(facecolor='white', figsize=(10, 10))\n",
    "            df = pd.DataFrame({'e1': embedding[:, 0], 'e2': embedding[:, 1], 'target': targets[key][target]})\n",
    "            \n",
    "            if target == 'argmax_pred':\n",
    "                df['target'] = [text_to_numerical_label[_] for _ in df['target'].values]\n",
    "            \n",
    "            im = axs.scatter(df['e1'].values, df['e2'].values, c=df['target'], cmap=cmap, s=s)\n",
    "            axs.set_aspect('equal')\n",
    "            fig.colorbar(im, ax=axs)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # uncomment if want to save\n",
    "            #plt.savefig('{}_{}_nn_{}_embedding.png'.format(key, target, n_neighbors), dpi=200)\n",
    "            #plt.close()\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

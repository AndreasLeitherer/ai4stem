{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223a3d1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T09:12:03.774424Z",
     "start_time": "2023-02-15T09:12:03.770625Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "from scipy import ndimage\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from scipy.signal import get_window\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "from scipy.stats import mode\n",
    "from scipy import stats\n",
    "from copy import deepcopy\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from ai4stem.utils.utils_data import load_pretrained_model, load_example_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826aebaa",
   "metadata": {},
   "source": [
    "# Necessary specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33deed8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T09:12:03.793233Z",
     "start_time": "2023-02-15T09:12:03.775703Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify path where to save the results:\n",
    "results_folder = '.'\n",
    "\n",
    "input_image = load_example_image()\n",
    "image_name = 'Fe_bcc'\n",
    "pixel_to_angstrom = 0.12452489444788318\n",
    "window_size = 12.\n",
    "stride_size = [36, 36]\n",
    "\n",
    "# If want to visualize local windows, set to true\n",
    "save_local_windows = False\n",
    "local_windows_path = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(input_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827bb9ff",
   "metadata": {},
   "source": [
    "The following cells do not have to be changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9f141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = {image_name: (input_image, \n",
    "                               pixel_to_angstrom)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613cee85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T09:12:04.010767Z",
     "start_time": "2023-02-15T09:12:03.796800Z"
    }
   },
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "model = load_pretrained_model()\n",
    "model_name = 'pretrained_model'\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196835a1",
   "metadata": {},
   "source": [
    "# Functions for calculating FFt, segmentation, and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb8d907",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T09:12:04.025862Z",
     "start_time": "2023-02-15T09:12:04.012647Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_fft(img, padding=(0, 0), power=2,\n",
    "             sigma=None, r_cut=None,\n",
    "             thresholding=False, apply_window=True, output_size=None,\n",
    "             output_shape=(64, 64)):\n",
    "    \"\"\"Given HAADF image, calculate HAADF-FFT descriptor\n",
    "    \n",
    "    Parameters: \n",
    "    \n",
    "    img: np.array\n",
    "        HAADF input image\n",
    "    padding: tuple\n",
    "        zero padding employed to bring image size to power of 2\n",
    "    power: int\n",
    "        Number by which FFT amplitude is exponentiated\n",
    "        in order to supress small fluctuations and\n",
    "        emphasize peaks\n",
    "    sigma: int\n",
    "        Width of gaussian window employed to cut out central\n",
    "        part of the FFT. In the standard setting (sigma=None),\n",
    "        no cutting employed.\n",
    "    r_cut: int\n",
    "        Size of rectangular window\n",
    "        that is used to cut the center of the FFT.\n",
    "        In the standard setting (sigma=None),\n",
    "        no cutting employed.\n",
    "    thresholding: bool\n",
    "        [incompletely implemented] If True, apply thresholding\n",
    "        procedure to mitigate influence of central peak\n",
    "    output_size: tuple\n",
    "        Output size of fft, if None, fft size will be given\n",
    "        by img.shape[0] and img.shape[1], if output size\n",
    "        larger than image size, crop image, if smaller, apply \n",
    "        zero padding \n",
    "    \"\"\"\n",
    "\n",
    "    # First step: normalize image\n",
    "    img = cv2.normalize(img, None,\n",
    "                       alpha=0, beta=1,\n",
    "                       norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    if apply_window:\n",
    "        # windowing\n",
    "        bw2d = np.outer(get_window('hanning',img.shape[0]), \n",
    "                        np.ones(img.shape[1]))\n",
    "        bw2d_1 = np.transpose(np.outer(get_window('hanning',img.shape[1]), \n",
    "                                       np.ones(img.shape[0])))\n",
    "        w = np.sqrt(bw2d * bw2d_1)\n",
    "        img_windowed = img * w\n",
    "    else:\n",
    "        img_windowed = img\n",
    "    \n",
    "    # Calculate FFT\n",
    "    f = np.fft.fft2(img_windowed, s=output_size)\n",
    "    \n",
    "    # Calculate power spectrum (or higher order exponential)\n",
    "    fshift = np.fft.fftshift(np.power(np.abs(f), power))\n",
    "    \n",
    "    # Normalization\n",
    "    fshift = cv2.normalize(fshift, None,\n",
    "                           alpha=0, beta=1,\n",
    "                           norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    \n",
    "    \n",
    "    # Remove central part of image, several options:\n",
    "    # Spherical cut:\n",
    "    if not r_cut == None:\n",
    "\n",
    "        xc = (fshift.shape[0] - 1.0) / 2.0\n",
    "        yc = (fshift.shape[1] - 1.0) / 2.0\n",
    "        # spherical mask\n",
    "        a, b = xc, yc\n",
    "        x, y = np.ogrid[-a:fshift.shape[0] - a, -b:fshift.shape[1] - b]\n",
    "\n",
    "        mask_out = x * x + y * y <= r_cut * r_cut\n",
    "\n",
    "        for i in range(fshift.shape[0]):\n",
    "            for j in range(fshift.shape[1]):\n",
    "                if mask_out[i, j]:\n",
    "                    fshift[i, j] = 0.0\n",
    "   \n",
    "    # cut using gaussian window: \n",
    "    if not sigma == None:\n",
    "        bw2d = np.outer(get_window(('gaussian', sigma), fshift.shape[0]), \n",
    "                    np.ones(fshift.shape[1]))\n",
    "        bw2d_1 = np.transpose(np.outer(get_window(('gaussian', sigma), fshift.shape[0]), \n",
    "                                       np.ones(fshift.shape[0])))\n",
    "        w = np.sqrt(bw2d * bw2d_1)\n",
    "        fshift = fshift * (1-w)\n",
    "\n",
    "    if thresholding:\n",
    "        # print(\"Threshold FFT spectrum\")\n",
    "        # Previous procedure employed by Byungchul\n",
    "        \"\"\"\n",
    "        intfft = np.sort(fshift.ravel())[::-1]\n",
    "        thresh = intfft[1]\n",
    "\n",
    "        output = fshift / thresh\n",
    "        #output[np.where(output[:]<0)] = 0 Neccessary?\n",
    "        output[np.where(output[:]>thresh)] = 1\n",
    "        \n",
    "        fshift = output\n",
    "        \"\"\"\n",
    "        # Chris:\n",
    "        fshift = cv2.normalize(fshift, None, \n",
    "                               alpha=0, beta=1, \n",
    "                               norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "        fshift = fshift/.1\n",
    "        fshift[fshift>1] = 1\n",
    "        fshift = cv2.normalize(fshift, None, \n",
    "                               alpha=0, beta=1, \n",
    "                               norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "        \n",
    "    \n",
    "    # Cut out 64x64 window around center of FFT\n",
    "    output = fshift\n",
    "    #output2 = np.zeros((64,64))\n",
    "    #for i in range(0,64):\n",
    "    #    for j in range(0,64):\n",
    "    #        output2[i,j] = output[int(float(output.shape[0])/float(2.0))-32+i,int(float(output.shape[1])/float(2.0))-32+j]\n",
    "\n",
    "    output2 = np.zeros(output_shape)\n",
    "    for i in range(0, output_shape[0]):\n",
    "        for j in range(0, output_shape[1]):\n",
    "            output2[i,j] = output[int(float(output.shape[0])/2.) - int(output_shape[0]/2.) + i,\n",
    "                                  int(float(output.shape[1])/2.0) - int(output_shape[1]/2.) + j]\n",
    "\n",
    "    \n",
    "    output2 = cv2.normalize(output2, None, \n",
    "                            alpha=0, beta=1, \n",
    "                            norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    \n",
    "    return output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40763959",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T09:12:04.040957Z",
     "start_time": "2023-02-15T09:12:04.028095Z"
    }
   },
   "outputs": [],
   "source": [
    "def localwindow(image_in, stride_size, pixel_max=100,\n",
    "                normalize_before_fft=False, normalize_after_window=False):\n",
    "    x_max = image_in.shape[0]\n",
    "    y_max = image_in.shape[1]\n",
    "\n",
    "    images = []\n",
    "    spm_pos = []\n",
    "\n",
    "    i = 0\n",
    "    ni = 0\n",
    "    while i < x_max-pixel_max:\n",
    "        j = 0\n",
    "        nj = 0\n",
    "        ni = ni + 1\n",
    "\n",
    "        while j < y_max-pixel_max:\n",
    "            nj = nj + 1\n",
    "            image = np.zeros((pixel_max,pixel_max))\n",
    "            for x in range(0,pixel_max):\n",
    "                for y in range(0,pixel_max):\n",
    "                    image[x,y] = image_in[x+i,y+j] \n",
    "            if normalize_before_fft:\n",
    "                image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "            \n",
    "            \"\"\"\n",
    "            filename = \"local_images_\" + str(ni) + \"_\" + str(nj)\n",
    "            plt.figure()\n",
    "            plt.imshow(image,cmap='gray')\n",
    "            #plt.colorbar()\n",
    "            #plt.draw()\n",
    "            plt.axis('off')\n",
    "            plt.savefig(filename + '.png',bbox_inches='tight',pad_inches=0)\n",
    "            plt.close()\n",
    "            np.save(filename + '.npy', image)\n",
    "\n",
    "            makeWindowingFFT.windowFFT(image,filename +'.png',normalize_after_window)\n",
    "            \"\"\"\n",
    "            j += stride_size[1]\n",
    "            images.append(image)\n",
    "            spm_pos.append([i, j])\n",
    "        i += stride_size[0]\n",
    "    return images, np.asarray(spm_pos), ni, nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f92f4dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T09:12:04.059856Z",
     "start_time": "2023-02-15T09:12:04.042265Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_with_uncertainty(data, model=None, model_type='classification', n_iter=1000):\n",
    "    \"\"\"This function allows to calculate the uncertainty of a neural network model using dropout.\n",
    "\n",
    "    This follows Chap. 3 in Yarin Gal's PhD thesis:\n",
    "    http://mlg.eng.cam.ac.uk/yarin/thesis/thesis.pdf\n",
    "\n",
    "    We calculate the uncertainty of the neural network predictions in the three ways proposed in Gal's PhD thesis,\n",
    "     as presented at pag. 51-54:\n",
    "    - variation_ratio: defined in Eq. 3.19\n",
    "    - predictive_entropy: defined in Eq. 3.20\n",
    "    - mutual_information: defined at pag. 53 (no Eq. number)\n",
    "\n",
    "    .. codeauthors:: Angelo Ziletti <angelo.ziletti@gmail.com>, Andreas Leitherer <andreas.leitherer@gmail.com\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    labels = []\n",
    "    results = []\n",
    "    for idx_iter in range(n_iter):\n",
    "        if (idx_iter % (int(n_iter) / 10 + 1)) == 0:\n",
    "            print(\"Performing forward pass: {0}/{1}\".format(idx_iter + 1, n_iter))\n",
    "\n",
    "        result = model.predict(data)\n",
    "        label = result.argmax(axis=-1)\n",
    "\n",
    "        labels.append(label)\n",
    "        results.append(result)\n",
    "\n",
    "    results = np.asarray(results)\n",
    "    prediction = results.mean(axis=0)\n",
    "\n",
    "    if model_type == 'regression':\n",
    "        predictive_variance = results.var(axis=0)\n",
    "        uncertainty = dict(predictive_variance=predictive_variance)\n",
    "\n",
    "    elif model_type == 'classification':\n",
    "        # variation ratio\n",
    "        mode, mode_count = stats.mode(np.asarray(labels))\n",
    "        variation_ratio = np.transpose(1. - mode_count.mean(axis=0) / float(n_iter))\n",
    "\n",
    "        # predictive entropy\n",
    "        # clip values to 1e-12 to avoid divergency in the log\n",
    "        prediction = np.clip(prediction, a_min=1e-12, a_max=None, out=prediction)\n",
    "        log_p_class = np.log2(prediction)\n",
    "        entropy_all_iteration = - np.multiply(prediction, log_p_class)\n",
    "        predictive_entropy = np.sum(entropy_all_iteration, axis=1)\n",
    "\n",
    "        # mutual information\n",
    "        # clip values to 1e-12 to avoid divergency in the log\n",
    "        results = np.clip(results, a_min=1e-12, a_max=None, out=results)\n",
    "        p_log_p_all = np.multiply(np.log2(results), results)\n",
    "        exp_p_omega = np.sum(np.sum(p_log_p_all, axis=0), axis=1)\n",
    "        mutual_information = predictive_entropy + 1. / float(n_iter) * exp_p_omega\n",
    "\n",
    "        uncertainty = dict(variation_ratio=variation_ratio, predictive_entropy=predictive_entropy,\n",
    "                           mutual_information=mutual_information)\n",
    "    else:\n",
    "        raise ValueError(\"Supported model types are 'classification' or 'regression'.\"\n",
    "                         \"model_type={} is not accepted.\".format(model_type))\n",
    "\n",
    "    return prediction, uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c86d9e0",
   "metadata": {},
   "source": [
    "# Analyze image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12961055",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T09:14:59.134088Z",
     "start_time": "2023-02-15T09:12:04.095860Z"
    }
   },
   "outputs": [],
   "source": [
    "# FFT HAADF descriptor settings\n",
    "sigma = None # optional parameter\n",
    "thresholding = True # very important\n",
    "n_iter = 100 # MC dropout samples\n",
    "\n",
    "\n",
    "counter = 0\n",
    "results_dict = defaultdict(dict)\n",
    "for key in filenames:\n",
    "\n",
    "    dx_origin = filenames[key][1]\n",
    "    filename = filenames[key][0]\n",
    "    name = key\n",
    "    \n",
    "    if type(filename) == str:\n",
    "        \n",
    "        img = cv2.imread(filename)\n",
    "        image = deepcopy(img[:, :, 0])\n",
    "    else:\n",
    "        image = filename\n",
    "    adapted_window_size = window_size * (1. / dx_origin)\n",
    "    adapted_window_size = int(round(adapted_window_size))\n",
    "    print('For image called {}, window {} [Angstrom] corresponds to {} pixels'.format(key, window_size, adapted_window_size))\n",
    "\n",
    "    sliced_images, spm_pos, ni, nj = localwindow(image, stride_size=stride_size, pixel_max=adapted_window_size)\n",
    "    np.save(os.path.join(results_folder, '{}_{}_images.npy'.format(name,\n",
    "                                                                       model_name)), sliced_images)\n",
    "    \n",
    "    fft_descriptors = []\n",
    "    for im in sliced_images:\n",
    "        fft_desc = calc_fft(im, sigma=sigma, thresholding=thresholding)\n",
    "        fft_descriptors.append(fft_desc)\n",
    "    np.save(os.path.join(results_folder, '{}_fft_desc.npy'.format(name)), np.asarray(fft_descriptors))\n",
    "\n",
    "    repeated_images = np.array([np.stack([_]) for _ in fft_descriptors])\n",
    "    repeated_images = np.moveaxis(repeated_images, 1, -1)\n",
    "\n",
    "\n",
    "    prediction, uncertainty = predict_with_uncertainty(repeated_images, \n",
    "                                                   model=model, \n",
    "                                                   model_type='classification', \n",
    "                                                   n_iter=n_iter)\n",
    "    np.save(os.path.join(results_folder, '{}_{}_predictions.npy'.format(name,\n",
    "                                                                       model_name)), prediction)\n",
    "    for key in uncertainty:\n",
    "        np.save(os.path.join(results_folder, '{}_{}_{}.npy'.format(name,\n",
    "                                                                  model_name,\n",
    "                                                                  key)), uncertainty[key])\n",
    "    argmax_pred = prediction.argmax(axis=-1)\n",
    "    argmax_pred = np.reshape(argmax_pred, (ni, nj))\n",
    "    mutinfo = uncertainty['mutual_information']\n",
    "    mutinfo = np.reshape(mutinfo, (ni, nj))\n",
    "\n",
    "    results_dict[model_name][name] = {}\n",
    "    results_dict[model_name][name]['Prediction'] = argmax_pred\n",
    "    results_dict[model_name][name]['Mutual information'] = mutinfo\n",
    "    results_dict[model_name][name]['Input Image'] = image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e15414",
   "metadata": {},
   "source": [
    "# Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff4e2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T09:14:59.956188Z",
     "start_time": "2023-02-15T09:14:59.135324Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 10})\n",
    "\n",
    "\n",
    "for key in filenames:\n",
    "    name = key\n",
    "\n",
    "    argmax_pred = results_dict[model_name][name]['Prediction']\n",
    "    mutinfo = results_dict[model_name][name]['Mutual information']\n",
    "    image = results_dict[model_name][name]['Input Image']\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(10, 10))\n",
    "\n",
    "\n",
    "    im1 = axs[0].imshow(image, cmap='gray')\n",
    "    fig.colorbar(im1, ax=axs[0], orientation='vertical')\n",
    "\n",
    "    im2 = axs[1].imshow(argmax_pred, cmap='tab20')\n",
    "    fig.colorbar(im2, ax=axs[1],  orientation='vertical')\n",
    "\n",
    "    im3 = axs[2].imshow(mutinfo, cmap='hot', vmin=0.0)\n",
    "    fig.colorbar(im3, ax=axs[2],  orientation='vertical')\n",
    "    \n",
    "    axs[0].axis('off')\n",
    "    axs[1].axis('off')\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6272e851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

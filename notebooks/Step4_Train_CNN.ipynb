{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffa39ead",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7848fa91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T17:25:23.601836Z",
     "start_time": "2023-02-18T17:25:21.686813Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.layers import Conv2D, LeakyReLU, MaxPool2D, Flatten, Dropout, Dense, Input\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "# from hyperopt import space_eval\n",
    "\n",
    "import os\n",
    "\n",
    "import csv\n",
    "import time\n",
    "from tensorflow.keras.regularizers import L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d8b452",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T17:32:38.991192Z",
     "start_time": "2023-02-18T17:32:38.986727Z"
    }
   },
   "outputs": [],
   "source": [
    "savepath_model = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971b0b1c",
   "metadata": {},
   "source": [
    "# Functions for model definition and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9de5d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T17:25:57.081734Z",
     "start_time": "2023-02-18T17:25:57.066730Z"
    }
   },
   "outputs": [],
   "source": [
    "def cnn_model(input_shape=(64, 64, 1), dropout=0.07,\n",
    "              alpha=0.0, nb_blocks = 3, filter_sizes=[32, 16, 8],\n",
    "              kernel_size=(3,3), nb_classes=10, l2_value=0.0):\n",
    "\n",
    "    if not len(filter_sizes) == nb_blocks:\n",
    "        raise ValueError(\"# filters must be compatible with nb_blocks.\")\n",
    "\n",
    "    l2_reg = L2(l2=l2_value)\n",
    "\n",
    "    inputs = Input(shape=input_shape, name='input')\n",
    "\n",
    "    convlayer_counter = 0\n",
    "    pooling_counter = 0\n",
    "    activation_counter = 0\n",
    "    dropout_counter = 0\n",
    "    for i, filters in enumerate(filter_sizes):\n",
    "        if i == 0:\n",
    "            x = inputs\n",
    "\n",
    "        for j in range(2): # repeat the following blocks 2 times\n",
    "\n",
    "            x = Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1),\n",
    "                       padding='same', kernel_initializer='Orthogonal',\n",
    "                       data_format=\"channels_last\", kernel_regularizer=l2_reg,\n",
    "                       name='Convolution_2D_{}'.format(convlayer_counter))(x)\n",
    "            convlayer_counter += 1\n",
    "            x = LeakyReLU(alpha=alpha, name='Leaky_ReLU_{}'.format(activation_counter))(x)\n",
    "            activation_counter += 1\n",
    "            x = Dropout(rate=dropout, name='Dropout_{}'.format(dropout_counter))(x, training=True)\n",
    "            dropout_counter += 1\n",
    "\n",
    "        if not i == (nb_blocks - 1):\n",
    "            # for last block, no max pooling done\n",
    "            x = MaxPool2D(pool_size=(2, 2), strides=(2, 2),\n",
    "                          data_format=\"channels_last\",\n",
    "                          name='MaxPooling2D_{}'.format(pooling_counter))(x)\n",
    "            pooling_counter += 1\n",
    "\n",
    "    x = Flatten(name='Flatten')(x)\n",
    "    x = Dense(128, name='Dense_1', kernel_regularizer=l2_reg, activation='relu')(x)\n",
    "    x = Dropout(rate=dropout,\n",
    "                name='dropout_{}'.format(dropout_counter))(x, training=True)\n",
    "    outputs = Dense(nb_classes, name='Dense_2', activation='softmax') (x)\n",
    "\n",
    "    model = tensorflow.keras.Model(inputs, outputs)\n",
    "\n",
    "    adam = Adam(beta_1=0.9, beta_2=0.999, decay=0.0)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4be893",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T17:31:16.724332Z",
     "start_time": "2023-02-18T17:31:16.718731Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_preds(data, model, n_iter=1000):\n",
    "\n",
    "    results = []\n",
    "    for idx in range(n_iter):\n",
    "        pred = model.predict(data, batch_size=2048)\n",
    "        results.append(pred)\n",
    "\n",
    "    results = np.asarray(results)\n",
    "    predictions = np.mean(results, axis=0)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b135c95c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T17:32:03.362876Z",
     "start_time": "2023-02-18T17:32:03.350484Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_test_model(model, X_train, y_train, X_val, y_val,\n",
    "                         epochs=100, batch_size=64, verbose=1, n_iter=1000):\n",
    "\n",
    "    callbacks_savepath = os.path.join(savepath_model, 'model_it_{}.h5'.format(ITERATION))\n",
    "\n",
    "    callbacks = []\n",
    "    monitor = 'val_loss'\n",
    "    mode = 'min'\n",
    "    # Alternative: monitor validation accuracy.\n",
    "    #monitor = 'val_categorical_accuracy'\n",
    "    #mode = 'max'    \n",
    "    save_model_per_epoch = ModelCheckpoint(callbacks_savepath, monitor=monitor, verbose=1,\n",
    "                                       save_best_only=True, mode=mode, period=1)\n",
    "    callbacks.append(save_model_per_epoch)\n",
    "\n",
    "    # Additional possibility: use Early stopping.\n",
    "    #es = EarlyStopping(monitor=monitor, mode=mode, patience=10)\n",
    "    #callbacks.append(es)\n",
    "\n",
    "    # Fit model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "                        verbose=verbose, validation_data=(X_val, y_val),\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "    optimal_model = load_model(callbacks_savepath)\n",
    "\n",
    "\n",
    "    train_pred = decode_preds(data=X_train, model=optimal_model, n_iter=n_iter)\n",
    "    acc_train = accuracy_score(y_true=y_train.argmax(axis=-1), y_pred = train_pred.argmax(axis=-1))\n",
    "\n",
    "    val_pred = decode_preds(data=X_val, model=optimal_model, n_iter=n_iter)\n",
    "    acc_val = accuracy_score(y_true=y_val.argmax(axis=-1), y_pred = val_pred.argmax(axis=-1))\n",
    "\n",
    "    return acc_train, acc_val, optimal_model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089c8d9c",
   "metadata": {},
   "source": [
    "# Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b1160e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T17:32:28.728389Z",
     "start_time": "2023-02-18T17:32:28.641199Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "X_pristine = np.load(os.path.join(save_path, 'X_fft.npy'))\n",
    "y_pristine = np.load(os.path.join(save_path, 'y.npy'))\n",
    "                     \n",
    "X_distorted = np.load(os.path.join(save_path, 'X_fft_distorted.npy'))\n",
    "y_distorted = np.load(os.path.join(save_path, 'y_fft_distorted_int.npy'))\n",
    "    \n",
    "num_classes = np.unique(y_pristine).size\n",
    "\n",
    "X = np.concatenate((X_pristine, X_distorted))\n",
    "y = np.concatenate((y_pristine, y_distorted))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,\n",
    "                                                  random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "y_val = tensorflow.keras.utils.to_categorical(y_val, num_classes=num_classes)\n",
    "\n",
    "\n",
    "print(X_train.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d297684c",
   "metadata": {},
   "source": [
    "# Define architecture (see scripts folder for hyperopt optimization protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905a6b00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T17:36:29.112825Z",
     "start_time": "2023-02-18T17:36:29.109463Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\"epochs\": 2, \n",
    "          \"batch_size\": 64,\n",
    "          \"alpha\": 0.0, \n",
    "          \"kernel_size\": (3,3),\n",
    "          \"architecture\": (3, [32, 16, 8]),\n",
    "          \"dropout\": 0.07, \n",
    "          \"l2_value\": 0.0}\n",
    "\n",
    "\n",
    "global ITERATION\n",
    "ITERATION = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd321147",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T17:41:10.996219Z",
     "start_time": "2023-02-18T17:36:29.334327Z"
    }
   },
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "\n",
    "\n",
    "model = cnn_model(input_shape=(64, 64, 1), dropout=params[\"dropout\"], alpha=params[\"alpha\"],\n",
    "                  nb_blocks=params[\"architecture\"][0], filter_sizes=params[\"architecture\"][1],\n",
    "                  kernel_size=params[\"kernel_size\"], nb_classes=np.unique(y_val.argmax(axis=-1)).size,\n",
    "                  l2_value=params['l2_value'])\n",
    "\n",
    "acc_training, acc_validation, model, history = train_and_test_model(model=model, batch_size=params['batch_size'],\n",
    "                                                                    epochs=params['epochs'],\n",
    "                                                                    X_train=X_train, y_train=y_train,\n",
    "                                                                    X_val=X_val, y_val=y_val, verbose=1,\n",
    "                                                                    n_iter=10)#1000)\n",
    "\n",
    "\n",
    "for key in history.history:\n",
    "    np.save(os.path.join(savepath_model, 'it_{}_{}.npy'.format(ITERATION, key)), history.history[key])\n",
    "\n",
    "\n",
    "t_end = time.time()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "eval_time = round(abs(t_start-t_end),3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418706c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T17:41:11.000104Z",
     "start_time": "2023-02-18T17:41:10.997437Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Final validation accuracy: {}'.format(acc_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd2bf6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

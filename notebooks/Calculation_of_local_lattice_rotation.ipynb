{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95597939",
   "metadata": {},
   "source": [
    "This notebook calculates the local lattice rotation, as described in Supplementary Note 1 of the ai4stem manuscript (Leitherer et al., 2023)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5eafc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:30:26.705558Z",
     "start_time": "2023-02-14T17:30:26.700388Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "from scipy import ndimage\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from scipy.signal import get_window\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "from scipy.stats import mode\n",
    "from scipy import stats\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import hyperspy\n",
    "import hyperspy.api as hs\n",
    "import atomap.api as am\n",
    "from ase import Atoms\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "\n",
    "import ase\n",
    "from ase import Atoms\n",
    "\n",
    "\n",
    "from ase.io import read\n",
    "from pycpd import RigidRegistration, AffineRegistration, DeformableRegistration\n",
    "from functools import partial\n",
    "from copy import deepcopy\n",
    "from scipt import stats\n",
    "\n",
    "from ase import Atoms\n",
    "from ase.neighborlist import NeighborList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6de3e03",
   "metadata": {},
   "source": [
    "# Define required input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad7f211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:30:26.718132Z",
     "start_time": "2023-02-14T17:30:26.707203Z"
    }
   },
   "outputs": [],
   "source": [
    "# Please specify\n",
    "# 1. Savepath, 2. STtride, 3. Window size\n",
    "# 4. image path 5. pixel / angstrom relation \n",
    "# 6. paths to mutual information and predictions (AI-STEM predictions)\n",
    "# This information can be found via the Zenodo link provided in the manuscript\n",
    "\n",
    "save_path = '.'\n",
    "\n",
    "stride_size = [12, 12]\n",
    "\n",
    "window_size = 136 # Cu example\n",
    "\n",
    "\n",
    "image_path = 'Cu_fcc_111.npy'\n",
    "pixel_to_angstrom = 0.088052397290637275\n",
    "mutual_information_pathh = 'Cu_fcc_111_mutual_information.npy'\n",
    "predictions_path = 'Cu_fcc_111_probabilities.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a94bf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:30:26.732410Z",
     "start_time": "2023-02-14T17:30:26.719418Z"
    }
   },
   "outputs": [],
   "source": [
    "# load argmax predictions, take most popular assignment as symmtery\n",
    "# for which the reference training image is loaded\n",
    "argmax_predictions = np.argmax(np.load(predictions_path), axis=-1)\n",
    "assigned_label = stats.mode(argmax_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef534cfe",
   "metadata": {},
   "source": [
    "# Load image, extract local windows, reconstruct atomic columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d063f1c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:30:26.764231Z",
     "start_time": "2023-02-14T17:30:26.753341Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function for calculating local windows\n",
    "\n",
    "def localwindow(image_in, stride_size, pixel_max=100,\n",
    "                normalize_before_fft=False, normalize_after_window=False):\n",
    "    x_max = image_in.shape[0]\n",
    "    y_max = image_in.shape[1]\n",
    "\n",
    "    images = []\n",
    "    spm_pos = []\n",
    "\n",
    "    i = 0\n",
    "    ni = 0\n",
    "    while i < x_max-pixel_max:\n",
    "        j = 0\n",
    "        nj = 0\n",
    "        ni = ni + 1\n",
    "\n",
    "        while j < y_max-pixel_max:\n",
    "            nj = nj + 1\n",
    "            image = np.zeros((pixel_max,pixel_max))\n",
    "            for x in range(0,pixel_max):\n",
    "                for y in range(0,pixel_max):\n",
    "                    image[x,y] = image_in[x+i,y+j] \n",
    "            if normalize_before_fft:\n",
    "                image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "            \n",
    "            \"\"\"\n",
    "            filename = \"local_images_\" + str(ni) + \"_\" + str(nj)\n",
    "            plt.figure()\n",
    "            plt.imshow(image,cmap='gray')\n",
    "            #plt.colorbar()\n",
    "            #plt.draw()\n",
    "            plt.axis('off')\n",
    "            plt.savefig(filename + '.png',bbox_inches='tight',pad_inches=0)\n",
    "            plt.close()\n",
    "            np.save(filename + '.npy', image)\n",
    "\n",
    "            makeWindowingFFT.windowFFT(image,filename +'.png',normalize_after_window)\n",
    "            \"\"\"\n",
    "            j += stride_size[1]\n",
    "            images.append(image)\n",
    "            spm_pos.append([i, j])\n",
    "        i += stride_size[0]\n",
    "    return images, np.asarray(spm_pos), ni, nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae38e845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:30:47.934902Z",
     "start_time": "2023-02-14T17:30:26.765741Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract local windows\n",
    "print(image_path)\n",
    "image = np.load(image_path)\n",
    "sliced_images, spm_pos, ni, nj = localwindow(image, stride_size=stride_size, pixel_max=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0ec3cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:30:47.941456Z",
     "start_time": "2023-02-14T17:30:47.936166Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function for reconstructing real-space lattice\n",
    "# from atomic columns via atomap\n",
    "def reconstruct_via_atomap(image, separation, refine=True):\n",
    "\n",
    "    separation_range = (separation - 1, separation + 1)\n",
    "    \n",
    "    peaks = am.get_feature_separation(image, separation_range=separation_range)\n",
    "    atom_positions = am.get_atom_positions(image, separation=separation)\n",
    "    \n",
    "    \n",
    "    if refine:\n",
    "        \n",
    "        min_peak_separation = separation\n",
    "        tr_img = hs.signals.Signal2D(image)\n",
    "\n",
    "        s_peaks = peaks #am.get_feature_separation(hs.signals.Signal2D(image),\n",
    "                  #                          separation_range=(min_peak_separation, min_peak_separation * 2),\n",
    "                  #                          show_progressbar=False)\n",
    "        # Get peak positions and determine sublattice\n",
    "        peak_pos = am.get_atom_positions(tr_img, separation=min_peak_separation)\n",
    "        peak_pos = am.Sublattice(peak_pos, image=tr_img.data)\n",
    "\n",
    "        # Refine peak positions using center of mass and 2D Gaussians based on NN distance\n",
    "        peak_pos.find_nearest_neighbors()\n",
    "        peak_pos.refine_atom_positions_using_center_of_mass()\n",
    "        peak_pos.refine_atom_positions_using_2d_gaussian()\n",
    "\n",
    "        #peak_pos.plot(navigator='signal')\n",
    "\n",
    "        # Covert peaks to array\n",
    "        peak_list = peak_pos.atom_list\n",
    "        num_peaks = np.shape(peak_list)\n",
    "        num_peaks = num_peaks[0]\n",
    "\n",
    "        peaks = np.zeros((num_peaks,2))\n",
    "        for i in range(0, num_peaks):\n",
    "            peaks[i,:] = [peak_list[i].pixel_x, peak_list[i].pixel_y]\n",
    "        atom_positions = peaks\n",
    "    \n",
    "    return atom_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902a274a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:30:50.257789Z",
     "start_time": "2023-02-14T17:30:47.942889Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "separation = 1. / pixel_to_angstrom\n",
    "print(separation)\n",
    "\n",
    "atomic_columns = reconstruct_via_atomap(hs.signals.Signal2D(image), separation=int(separation / 2.), refine=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaba830",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:30:50.847848Z",
     "start_time": "2023-02-14T17:30:50.260200Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(15, 15))\n",
    "plt.imshow(image)\n",
    "plt.scatter(atomic_columns[:, 0], atomic_columns[:, 1], s=4, c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ac00e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:30:53.625709Z",
     "start_time": "2023-02-14T17:30:50.849401Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract atomic colums for each local window (local window calculated earlier from image)\n",
    "\n",
    "\n",
    "start = [window_size, window_size]\n",
    "element_agnostic = False\n",
    "coordinate_vectors = atomic_columns\n",
    "element_symbols = np.array(['Ti' for _ in range(len(atomic_columns[:, 0]))], dtype=object)\n",
    "\n",
    "number_of_strides_vector = [ni, nj]\n",
    "\n",
    "x_sliding_volume_edge_length = window_size\n",
    "y_sliding_volume_edge_length = window_size\n",
    "step_size_x = stride_size[0]\n",
    "step_size_y = stride_size[1]\n",
    "x_min = 0\n",
    "y_min = 0\n",
    "\n",
    "all_boxes = []\n",
    "all_stride_idx = []\n",
    "\n",
    "list_of_xy_boxes = []\n",
    "number_of_atoms_xy = []\n",
    "\n",
    "for i in range(number_of_strides_vector[1]):\n",
    "\n",
    "    list_of_x_boxes = []\n",
    "    number_of_atoms_x = []\n",
    "\n",
    "    for j in range(number_of_strides_vector[0]):\n",
    "\n",
    "        # Determine atoms within sliding box\n",
    "        positionvectors_within_sliding_volume = []\n",
    "        element_names_within_sliding_volume = ''\n",
    "\n",
    "\n",
    "        condition = (coordinate_vectors[:,0] <= start[0]) & (coordinate_vectors[:,1] <= start[1]) \\\n",
    "                    & (coordinate_vectors[:,0] >= (start[0]-x_sliding_volume_edge_length)) \\\n",
    "                    & (coordinate_vectors[:,1] >= (start[1]-y_sliding_volume_edge_length))\n",
    "        positionvectors_within_sliding_volume = coordinate_vectors[condition]\n",
    "        element_names_within_sliding_volume = element_symbols[condition]\n",
    "        element_names_within_sliding_volume = ''.join(list(element_names_within_sliding_volume))\n",
    "        \n",
    "        positionvectors_within_sliding_volume = np.array([[_[0], \n",
    "                                                           _[1],\n",
    "                                                          0.0] for _ in positionvectors_within_sliding_volume])\n",
    "\n",
    "        if len(positionvectors_within_sliding_volume) == 0:\n",
    "            number_of_atoms_x.append(0)\n",
    "\n",
    "            element_name = element_names_within_sliding_volume  # should be ''\n",
    "            # create ase Atoms object Atoms(symbols='',pbc=False)\n",
    "            atoms_within_sliding_volume = ase.Atoms(element_name)\n",
    "            # Optional: assign label\n",
    "            # atoms_within_sliding_volume.info['label']='box_label_'+str(i)+str(j)+str(k)\n",
    "            atoms_within_sliding_volume.set_pbc(False) # added for safety\n",
    "            list_of_x_boxes.append(atoms_within_sliding_volume)\n",
    "\n",
    "        else:\n",
    "            number_of_atoms_x.append(len(positionvectors_within_sliding_volume))\n",
    "\n",
    "            if element_agnostic:\n",
    "                element_name = 'Fe'+str(len(positionvectors_within_sliding_volume))\n",
    "            else:\n",
    "                element_name = element_names_within_sliding_volume\n",
    "            atoms_within_sliding_volume = ase.Atoms(element_name, positionvectors_within_sliding_volume)\n",
    "            # Optional: assign label\n",
    "            # atoms_within_sliding_volume.info['label']='box_label_'+str(i)+str(j)+str(k)\n",
    "            atoms_within_sliding_volume.set_pbc(False) # added for safety\n",
    "            list_of_x_boxes.append(atoms_within_sliding_volume)\n",
    "        all_boxes.append([[_[0], _[1]] for _ in positionvectors_within_sliding_volume])\n",
    "        all_stride_idx.append([j, i])\n",
    "\n",
    "        start[0] += step_size_x\n",
    "\n",
    "    number_of_atoms_xy.append(number_of_atoms_x)\n",
    "    list_of_xy_boxes.append(list_of_x_boxes)\n",
    "    start[0] = x_min+x_sliding_volume_edge_length  # Reset x_value after most inner for loop finished\n",
    "    start[1] += step_size_y  # next y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae9257",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:30:55.136400Z",
     "start_time": "2023-02-14T17:30:53.626696Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize some of the local windows\n",
    "for idx in range(len(sliced_images))[::500]:\n",
    "    img = sliced_images[idx]\n",
    "    pos = all_boxes[idx]\n",
    "    pos = np.array(pos)\n",
    "    pos[:, 0] -= all_stride_idx[idx][0] * stride_size[0]\n",
    "    pos[:, 1] -= all_stride_idx[idx][1] * stride_size[1]\n",
    "                 \n",
    "    fig, axs = plt.subplots()\n",
    "    axs.imshow(img)\n",
    "    if not len(pos) == 0:\n",
    "        pos = np.array(pos)\n",
    "        axs.scatter(pos[:, 0], pos[:, 1], c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf2c99c",
   "metadata": {},
   "source": [
    "# Given predicted symmetry, define reference lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f8402b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:30:55.157252Z",
     "start_time": "2023-02-14T17:30:55.143293Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load all reference lattices\n",
    "reference_data_path = '/home/leitherer/Real_space_AI_STEM/ai4stem/data/AISTEM/Convolution/sim_test'\n",
    "\n",
    "reference_pixeltoangstrom = 0.12\n",
    "\n",
    "file_ending = 'sampling_0.12_convolved_STEM_image.hdf5'\n",
    "\n",
    "reference_dict = {\"BCC_Fe_100\": os.path.join(reference_data_path, '{}_LatPar_{}A_{}'.format('BCC_Fe_100', \n",
    "                                                                                           2.87, \n",
    "                                                                                           file_ending)),\n",
    " \"BCC_Fe_110\": os.path.join(reference_data_path, '{}_LatPar_{}A_{}'.format('BCC_Fe_110', \n",
    "                                                                          2.87, \n",
    "                                                                          file_ending)),\n",
    " \"BCC_Fe_111\": os.path.join(reference_data_path, '{}_LatPar_{}A_{}'.format('BCC_Fe_111', \n",
    "                                                                          2.87, \n",
    "                                                                          file_ending)),\n",
    " \"FCC_Cu_100\": os.path.join(reference_data_path, '{}_LatPar_{}A_{}'.format('FCC_Cu_100', \n",
    "                                                                          3.63, \n",
    "                                                                          file_ending)),\n",
    " \"FCC_Cu_110\": os.path.join(reference_data_path, '{}_LatPar_{}A_{}'.format('FCC_Cu_110', \n",
    "                                                                          3.63, \n",
    "                                                                          file_ending)),\n",
    " \"FCC_Cu_111\": os.path.join(reference_data_path, '{}_LatPar_{}A_{}'.format('FCC_Cu_111', \n",
    "                                                                          3.63, \n",
    "                                                                          file_ending)),\n",
    " \"FCC_Cu_211\": os.path.join(reference_data_path, '{}_LatPar_{}A_{}'.format('FCC_Cu_211', \n",
    "                                                                          3.63, \n",
    "                                                                          file_ending)),\n",
    " \"HCP_Ti_0001\": os.path.join(reference_data_path, '{}_LatPar_{}A_{}'.format('HCP_Ti_0001', \n",
    "                                                                           2.95, \n",
    "                                                                           file_ending)),\n",
    " \"HCP_Ti_10m10\": os.path.join(reference_data_path, '{}_LatPar_{}A_{}'.format('HCP_Ti_10m10', \n",
    "                                                                            2.95, \n",
    "                                                                            file_ending)),\n",
    " \"HCP_Ti_2m1m10\": os.path.join(reference_data_path, '{}_LatPar_{}A_{}'.format('HCP_Ti_2m1m10', \n",
    "                                                                             2.95, \n",
    "                                                                             file_ending))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcda445",
   "metadata": {},
   "source": [
    "Load training image for currently assigned label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766abf5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:30:55.322746Z",
     "start_time": "2023-02-14T17:30:55.179301Z"
    }
   },
   "outputs": [],
   "source": [
    "training_path = reference_dict[assigned_label]\n",
    "print(training_path)\n",
    "\n",
    "training_file = h5py.File(training_path,'r')\n",
    "\n",
    "img = training_file.get('convolved_stem_image/conv_stem')\n",
    "\n",
    "tr_img = np.array(img)\n",
    "print(tr_img.shape)\n",
    "\n",
    "plt.imshow(tr_img)\n",
    "training_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67a97ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:31:06.621227Z",
     "start_time": "2023-02-14T17:30:55.323797Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reconstruct real-space lattice\n",
    "\n",
    "ref_separation = int( (1. / reference_pixeltoangstrom) / 2. )\n",
    "print(ref_separation)\n",
    "\n",
    "\n",
    "atom_positions = reconstruct_via_atomap(hs.signals.Signal2D(tr_img), separation= ref_separation, refine=False)\n",
    "fig, axs = plt.subplots(figsize=(20,20))\n",
    "axs.set_aspect('equal')\n",
    "plt.scatter(atom_positions[:, 0], atom_positions[:, 1], s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af5d990",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:31:06.642143Z",
     "start_time": "2023-02-14T17:31:06.630003Z"
    }
   },
   "outputs": [],
   "source": [
    "# Given input window size, extract same window size from training image.\n",
    "# Assume adjusted window size -> need to adjust window used for mask!\n",
    "\n",
    "# 1. convert given window size into angstrom\n",
    "window_input_angstrom = float(window_size) * pixel_to_angstrom\n",
    "window_reference = window_input_angstrom * ( 1. / float(reference_pixeltoangstrom))\n",
    "print(round(window_reference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d7d061",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:31:06.741591Z",
     "start_time": "2023-02-14T17:31:06.643855Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract segment from center of reference image, \n",
    "center = np.mean(atom_positions, axis=0)\n",
    "print(center)\n",
    "\n",
    "\n",
    "mask_x = (atom_positions[:, 0] >= (center[0] - float(window_reference) / 2.)) & \\\n",
    "         (atom_positions[:, 0] <= (center[0] + float(window_reference) / 2.))\n",
    "mask_y = (atom_positions[:, 1] >= (center[1] - float(window_reference) / 2.)) & \\\n",
    "         (atom_positions[:, 1] <= (center[1] + float(window_reference) / 2.))\n",
    "    \n",
    "mask = mask_x & mask_y\n",
    "filtered_columns = atom_positions[mask]\n",
    "fig, axs = plt.subplots()\n",
    "axs.set_aspect('equal')\n",
    "plt.scatter(filtered_columns[:, 0], filtered_columns[:, 1], s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b4b7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:31:06.862050Z",
     "start_time": "2023-02-14T17:31:06.761127Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize extracted reference lattice and then extract small local\n",
    "# region (not more than 20 atoms, i.e., few neareast neighbors)\n",
    "\n",
    "reference_lattice = deepcopy(filtered_columns)\n",
    "# Shift to origin\n",
    "x_shift = np.mean(reference_lattice[:,0])\n",
    "y_shift = np.mean(reference_lattice[:,1])\n",
    "\n",
    "dist = np.zeros((reference_lattice.shape[0],1))\n",
    "for p in range(reference_lattice.shape[0]):\n",
    "    dist[p] = np.sqrt( (reference_lattice[p,0]-x_shift)**2 + (reference_lattice[p,1]-y_shift)**2 )\n",
    "\n",
    "reference_lattice_cent = reference_lattice[np.argmin(dist)]\n",
    "\n",
    "reference_lattice[:,0] = reference_lattice[:,0] - reference_lattice_cent[0]\n",
    "reference_lattice[:,1] = reference_lattice[:,1] - reference_lattice_cent[1]\n",
    "\n",
    "# Delete atoms until have only few nearest neighbors (20)\n",
    "radius = float(window_reference) / 2.\n",
    "reference_lattice_tmp = deepcopy(reference_lattice)\n",
    "Nat = 20\n",
    "delta = (1. / pixel_to_angstrom) / 8.\n",
    "while len(reference_lattice_tmp) >= Nat:\n",
    "    del_peaks = np.sqrt(reference_lattice_tmp[:,0]**2 + reference_lattice_tmp[:,1]**2) < radius\n",
    "    reference_lattice_tmp = reference_lattice_tmp[del_peaks == True]\n",
    "    radius -= delta\n",
    "reference_lattice = reference_lattice_tmp\n",
    "print(len(reference_lattice))    \n",
    "fig, axs = plt.subplots()\n",
    "axs.set_aspect('equal')\n",
    "plt.scatter(reference_lattice[:, 0], reference_lattice[:, 1], s=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14edf3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:31:06.909422Z",
     "start_time": "2023-02-14T17:31:06.894804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define function for normalizign the lattice\n",
    "\n",
    "def norm_window_lattice(atomic_columns):\n",
    "    \n",
    "    # Select box\n",
    "    peaks_box = np.array(atomic_columns)\n",
    "  \n",
    "    # Shift to origin\n",
    "    x_shift = np.mean(peaks_box[:,0])\n",
    "    y_shift = np.mean(peaks_box[:,1])\n",
    "\n",
    "    dist = np.zeros((peaks_box.shape[0],1))\n",
    "    for p in range(peaks_box.shape[0]):\n",
    "        dist[p] = np.sqrt( (peaks_box[p,0]-x_shift)**2 + (peaks_box[p,1]-y_shift)**2 )\n",
    "\n",
    "    peaks_box_cent = peaks_box[np.argmin(dist)]\n",
    "\n",
    "    peaks_box[:,0] = peaks_box[:,0] - peaks_box_cent[0]\n",
    "    peaks_box[:,1] = peaks_box[:,1] - peaks_box_cent[1]\n",
    "\n",
    "    # Apply radial mask\n",
    "    #\"\"\"\n",
    "    delta = (1. / pixel_to_angstrom) / 8.\n",
    "    radius = float(window_size) / 2. #50\n",
    "    while peaks_box.shape[0] > reference_lattice.shape[0]:\n",
    "        del_peaks = np.sqrt(peaks_box[:,0]**2 + peaks_box[:,1]**2) < radius\n",
    "        peaks_box = peaks_box[del_peaks == True]  \n",
    "        \n",
    "        radius = radius - delta\n",
    "\n",
    "    lattice = peaks_box\n",
    "    \n",
    "    return lattice\n",
    "    #\"\"\"\n",
    "    #\n",
    "    #return peaks_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8156a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:31:06.923716Z",
     "start_time": "2023-02-14T17:31:06.910793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define criterion according to which the local rotation angle is calculated\n",
    "# Reason: algorithm performs clock- or counter-clockwise rotation. \n",
    "# Thus need to adjust.\n",
    "\n",
    "\n",
    "# All rotation symmetries\n",
    "rotations_dict = {\"BCC_Fe_100\": 90.,\n",
    "                  \"BCC_Fe_110\": 180., \n",
    "                  \"BCC_Fe_111\": 60., \n",
    "                  \"FCC_Cu_100\": 90., \n",
    "                  \"FCC_Cu_110\": 60., \n",
    "                  \"FCC_Cu_111\": 60., \n",
    "                  \"FCC_Cu_211\": 180., \n",
    "                  \"HCP_Ti_0001\": 60., \n",
    "                  \"HCP_Ti_10m10\": 180., \n",
    "                  \"HCP_Ti_2m1m10\": 60.}\n",
    "\n",
    "\n",
    "def criterion(assigned_label, mismatch_angle):\n",
    "    mismatch_angle = np.abs(mismatch_angle)\n",
    "    \n",
    "    symmetry_angle = rotations_dict[assigned_label]\n",
    "    max_angle = symmetry_angle / 2.\n",
    "    # eg for Ti, rot sym angle is 60., max angle is 30: If calculated\n",
    "    # mismatch angle is larger than 30., simply subtract 60. - in\n",
    "    # this way the caculated mismatch angle is the smallest angle \n",
    "    # to match reference lattice and local window columns\n",
    "    \n",
    "    if mismatch_angle >= max_angle:\n",
    "        mismatch_angle -= symmetry_angle\n",
    "        mismatch_angle = np.abs(mismatch_angle)\n",
    "    return mismatch_angle\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ed9030",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:31:06.941498Z",
     "start_time": "2023-02-14T17:31:06.925389Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function for scaling lattice isotropically\n",
    "def get_nn_distance(atoms, distribution='quantile_nn', cutoff=20.0,\n",
    "                    min_nb_nn=1,#5,\n",
    "                    pbc=True, plot_histogram=False, bins=100, \n",
    "                    constrain_nn_distances=False, nn_distances_cutoff=0.9, \n",
    "                    element_sensitive=False, central_atom_species=26, neighbor_atoms_species=26,\n",
    "                    return_more_nn_distances=False, return_histogram=False):\n",
    "    \n",
    "    if not pbc:\n",
    "        atoms.set_pbc((False, False, False))\n",
    "\n",
    "    nb_atoms = atoms.get_number_of_atoms()\n",
    "    cutoffs = np.ones(nb_atoms) * cutoff\n",
    "    # Notice that if get_neighbors(a) gives atom b as a neighbor,\n",
    "    #    then get_neighbors(b) will not return a as a neighbor - unless\n",
    "    #    bothways=True was used.\"\n",
    "    nl = NeighborList(cutoffs, skin=0.1, self_interaction=False, bothways=True)\n",
    "    # nl.build(atoms) previously used.\n",
    "    nl.update(atoms)\n",
    "    nn_dist = []\n",
    "\n",
    "    for idx in range(nb_atoms):\n",
    "        # element sensitive part - only select atoms of specified chemical species as central atoms\n",
    "        if element_sensitive:\n",
    "            if atoms.get_atomic_numbers()[idx]==central_atom_species:\n",
    "                pass\n",
    "            else:\n",
    "                continue        \n",
    "        \n",
    "        #print(\"List of neighbors of atom number {0}\".format(idx))\n",
    "        indices, offsets = nl.get_neighbors(idx)\n",
    "        if len(indices) >= min_nb_nn: # before was >!!\n",
    "            coord_central_atom = atoms.positions[idx]\n",
    "            # get positions of nearest neighbors within the cut-off\n",
    "            dist_list = []\n",
    "            for i, offset in zip(indices, offsets):\n",
    "                # element sensitive part - only select neighbors of specified chemical species\n",
    "                if element_sensitive:\n",
    "                    if atoms.get_atomic_numbers()[i]==neighbor_atoms_species:\n",
    "                        pass\n",
    "                    else:\n",
    "                        continue\n",
    "                # center each neighbors wrt the central atoms\n",
    "                coord_neighbor = atoms.positions[i] + np.dot(offset, atoms.get_cell())\n",
    "                # calculate distance between the central atoms and the neighbors\n",
    "                dist = np.linalg.norm(coord_neighbor - coord_central_atom)\n",
    "                dist_list.append(dist)\n",
    "\n",
    "            # dist_list is the list of distances from the central_atoms\n",
    "            if len(sorted(dist_list)) > 0:\n",
    "                # get nearest neighbor distance\n",
    "                nn_dist.append(sorted(dist_list)[0])\n",
    "            else:\n",
    "                print(\"List of neighbors is empty for some atom. Cutoff must be increased.\")\n",
    "                return None\n",
    "        else:\n",
    "            print(\"Atom {} has less than {} neighbours. Skipping.\".format(idx, min_nb_nn))\n",
    "\n",
    "\n",
    "    if constrain_nn_distances:\n",
    "         original_length = len(nn_dist)\n",
    "         # Select all nearest neighbor distances larger than nn_distances_cutoff\n",
    "         threshold_indices = np.array(nn_dist) > nn_distances_cutoff \n",
    "         nn_dist = np.extract(threshold_indices , nn_dist)\n",
    "         if len(nn_dist)<original_length:\n",
    "             print(\"Number of nn distances has been reduced from {} to {}.\".format(original_length,len(nn_dist)))\n",
    "\n",
    "    if distribution == 'avg_nn':\n",
    "        length_scale = np.mean(nn_dist)\n",
    "    elif distribution == 'quantile_nn':\n",
    "        # get the center of the maximally populated bin\n",
    "        hist, bin_edges = np.histogram(nn_dist, bins=bins, density=False)\n",
    "\n",
    "        # scale by r**2 because this is how the rdf is defined\n",
    "        # the are of the spherical shells grows like r**2\n",
    "        hist_scaled = []\n",
    "        for idx_shell, hist_i in enumerate(hist):\n",
    "            hist_scaled.append(float(hist_i)/(bin_edges[idx_shell]**2))\n",
    "\n",
    "        length_scale = (bin_edges[np.argmax(hist_scaled)] + bin_edges[np.argmax(hist_scaled) + 1]) / 2.0\n",
    "\n",
    "        if plot_histogram:\n",
    "            # this histogram is not scaled by r**2, it is only the count\n",
    "            plt.hist(nn_dist, bins=bins)  # arguments are passed to np.histogram\n",
    "            plt.title(\"Histogram\")\n",
    "            plt.show()\n",
    "    else:\n",
    "        raise ValueError(\"Not recognized option for atoms_scaling. \"\n",
    "                         \"Possible values are: 'min_nn', 'avg_nn', or 'quantile_nn'.\")\n",
    "                         \n",
    "    if return_more_nn_distances and distribution=='quantile_nn':\n",
    "        length_scale_3 = (bin_edges[np.argsort(hist_scaled)[-3:][0]] + bin_edges[np.argsort(hist_scaled)[-3:][0] + 1]) / 2.0\n",
    "        length_scale_2 = (bin_edges[np.argsort(hist_scaled)[-3:][1]] + bin_edges[np.argsort(hist_scaled)[-3:][1] + 1]) / 2.0\n",
    "        return length_scale, length_scale_2, length_scale_3\n",
    "    elif return_histogram:\n",
    "        return length_scale, hist_scaled, nn_dist\n",
    "    else:\n",
    "        return length_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e015d62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:31:06.971763Z",
     "start_time": "2023-02-14T17:31:06.957725Z"
    }
   },
   "outputs": [],
   "source": [
    "def scale_lattice(lattice, window_size):\n",
    "    atoms = Atoms(np.full(len(lattice), 'Fe'), \n",
    "                  positions=[[_[0], _[1], 0.0] for _ in lattice])\n",
    "    \n",
    "    nn_distance = get_nn_distance(atoms, cutoff=window_size)\n",
    "    \n",
    "    return np.array(lattice) / nn_distance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573490bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:31:07.003890Z",
     "start_time": "2023-02-14T17:31:06.986316Z"
    }
   },
   "outputs": [],
   "source": [
    "reference_lattice_scaled = scale_lattice(reference_lattice,\n",
    "                                         window_reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9e3143",
   "metadata": {},
   "source": [
    "# Calculate mismatch angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07560f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:32:31.896019Z",
     "start_time": "2023-02-14T17:31:07.022827Z"
    }
   },
   "outputs": [],
   "source": [
    "mismatch_angles = []\n",
    "\n",
    "input_lattice = []\n",
    "transformed_reflattice = []\n",
    "regs = []\n",
    "\n",
    "for idx, pos in enumerate(all_boxes):\n",
    "\n",
    "    if idx % 1000 == 0:\n",
    "        print('Process box {} / {}'.format(idx, len(all_boxes)))\n",
    "        \n",
    "    # X: target, Y: source\n",
    "    Y = reference_lattice_scaled \n",
    "    \n",
    "    X = norm_window_lattice(pos) \n",
    "    X = scale_lattice(X, window_size)\n",
    "    \n",
    "    # AffineRegistration\n",
    "    reg = RigidRegistration(**{'X': X, 'Y': Y, 'max_iterations': 100})\n",
    "    reg.register()\n",
    "\n",
    "    mismatch_angle = (-1) * np.arcsin(reg.get_registration_parameters()[1][0][1]) * 180 / np.pi\n",
    "\n",
    "    mismatch_angle = criterion(assigned_label, mismatch_angle)\n",
    "    mismatch_angles.append(mismatch_angle)\n",
    "    \n",
    "    transformed_reflattice.append(reg.transform_point_cloud(Y))\n",
    "    regs.append(reg)\n",
    "    input_lattice.append(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2854ecc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:32:31.904463Z",
     "start_time": "2023-02-14T17:32:31.897538Z"
    }
   },
   "outputs": [],
   "source": [
    "# statistics of calculated mismatch angles\n",
    "print('Min: {}, Max: {}, 5% quantile: {}, 95% quantile: {}'.format(np.min(mismatch_angles),\n",
    "                                                                   np.max(mismatch_angles),\n",
    "                                                                   np.quantile(mismatch_angles, 0.05),\n",
    "                                                                   np.quantile(mismatch_angles, 0.95)))\n",
    "\n",
    "vmin = np.quantile(mismatch_angles, 0.05)\n",
    "vmax = np.quantile(mismatch_angles, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91a82ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:32:32.395630Z",
     "start_time": "2023-02-14T17:32:31.905547Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmap = 'plasma'\n",
    "fig, axs = plt.subplots(figsize=(15, 15))\n",
    "plt.imshow(np.reshape(mismatch_angles, (ni, nj)), \n",
    "           vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bcd059",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T13:16:17.318149Z",
     "start_time": "2023-01-30T13:16:17.298100Z"
    }
   },
   "source": [
    "# Apply smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d12ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:32:32.988506Z",
     "start_time": "2023-02-14T17:32:32.396925Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d\n",
    "nber_nn = [1, 2, 4, 8, 16]\n",
    "data = np.reshape(mismatch_angles, (ni, nj))\n",
    "results = {}\n",
    "fig, ax = plt.subplots(1, len(nber_nn), facecolor='white', figsize=(25, 5))\n",
    "for idx, n in enumerate(nber_nn):\n",
    "    kernel = np.ones((n, n))\n",
    "    \n",
    "    # remove parts of image where mutual information is above threshold\n",
    "    mutinfo = np.load(results_path)\n",
    "    mask = mutinfo < 0.1\n",
    "    data_filtered = data.flatten()\n",
    "    data_filtered[~mask] = 0.0\n",
    "    data_filtered = np.reshape(data_filtered, (ni, nj))\n",
    "    \n",
    "    smoothed_data = convolve2d(data_filtered, kernel, boundary='symm', mode='same') / float(n * n)\n",
    "    #print(data.shape, smoothed_data.shape)\n",
    "    \n",
    "    vmin = np.quantile(smoothed_data.flatten()[mask], 0.05)\n",
    "    vmax = np.quantile(smoothed_data.flatten()[mask], 0.95)\n",
    "    print(vmin, vmax)\n",
    "    \n",
    "    axs = ax[idx]\n",
    "    \n",
    "    smoothed_data = smoothed_data.flatten()\n",
    "    smoothed_data[~mask] = np.nan\n",
    "    cmap = plt.get_cmap('plasma')\n",
    "    cmap.set_bad('gray')\n",
    "    smoothed_data = np.reshape(smoothed_data, (ni, nj))\n",
    "    \n",
    "    im = axs.imshow(smoothed_data, vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "    axs.set_title('NN = {}'.format(n))\n",
    "    fig.colorbar(im, ax=axs)\n",
    "    results[n] = smoothed_data\n",
    "    \n",
    "    np.save('./mismatch_results/{}_mismatch_w_smoothing_nn_{}.npy'.format(assigned_label, n), smoothed_data)\n",
    "plt.savefig('./mismatch_results/{}_mismatch_w_smoothing.svg'.format(assigned_label))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5431afbe",
   "metadata": {},
   "source": [
    "# Visulize, exemplarily, local lattice reconstructions with fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95e0622",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T17:32:35.337196Z",
     "start_time": "2023-02-14T17:32:32.989774Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx in range(len(sliced_images))[510:520]:\n",
    "    img = sliced_images[idx]\n",
    "    pos = all_boxes[idx]\n",
    "    pos = np.array(pos)\n",
    "    pos[:, 0] -= all_stride_idx[idx][0] * stride_size[0]\n",
    "    pos[:, 1] -= all_stride_idx[idx][1] * stride_size[1]\n",
    "    \n",
    "    mismatch_angle = mismatch_angles[idx] #regs[idx].get_registration_parameters()[1][0][0] # mismatch_angles[idx]\n",
    "\n",
    "    ref_lattice = transformed_reflattice[idx]\n",
    "    in_lattice = np.array(input_lattice[idx])\n",
    "    \n",
    "    \n",
    "        \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 10))\n",
    "    axs[0].imshow(img)\n",
    "    if not len(pos) == 0:\n",
    "        pos = np.array(pos)\n",
    "        axs[0].scatter(pos[:, 0], pos[:, 1], c='r')\n",
    "        axs[0].set_title('Pos {}, Mismatch angle = {},\\n DNat = {}'.format(spm_pos[idx],\n",
    "                                                                           mismatch_angle,\n",
    "                                                                           (len(in_lattice) - len(ref_lattice))))\n",
    "        \n",
    "        axs[1].scatter(in_lattice[:, 0], in_lattice[:, 1], marker='o', s=35, label='Reconstructed columns')\n",
    "        axs[1].scatter(ref_lattice[:, 0], ref_lattice[:, 1], marker='x', s =35, label='Fit')\n",
    "        axs[1].legend()\n",
    "        \n",
    "        axs[0].set_aspect('equal')\n",
    "        axs[1].set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb9aad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
